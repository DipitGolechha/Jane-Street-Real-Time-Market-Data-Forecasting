{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ca9940",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T14:54:53.181379Z",
     "iopub.status.busy": "2024-11-26T14:54:53.181092Z",
     "iopub.status.idle": "2024-11-26T14:54:53.921769Z",
     "shell.execute_reply": "2024-11-26T14:54:53.920910Z"
    },
    "papermill": {
     "duration": 0.746553,
     "end_time": "2024-11-26T14:54:53.923574",
     "exception": false,
     "start_time": "2024-11-26T14:54:53.177021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jane-street-real-time-market-data-forecasting/responders.csv\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/sample_submission.csv\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/features.csv\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=4/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=5/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=6/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=3/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=1/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=8/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=2/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=7/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_gateway.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_inference_server.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780f5f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T14:54:53.930443Z",
     "iopub.status.busy": "2024-11-26T14:54:53.930085Z",
     "iopub.status.idle": "2024-11-26T14:54:59.979918Z",
     "shell.execute_reply": "2024-11-26T14:54:59.979119Z"
    },
    "papermill": {
     "duration": 6.055471,
     "end_time": "2024-11-26T14:54:59.981965",
     "exception": false,
     "start_time": "2024-11-26T14:54:53.926494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cudf\n",
    "# Load the cudf.pandas extension for pandas-like GPU acceleration\n",
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c01c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T14:54:59.989102Z",
     "iopub.status.busy": "2024-11-26T14:54:59.988601Z",
     "iopub.status.idle": "2024-11-26T14:55:10.803775Z",
     "shell.execute_reply": "2024-11-26T14:55:10.803048Z"
    },
    "papermill": {
     "duration": 10.820837,
     "end_time": "2024-11-26T14:55:10.805782",
     "exception": false,
     "start_time": "2024-11-26T14:54:59.984945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing partition 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (5022952, 92)\n"
     ]
    }
   ],
   "source": [
    "    k = 4\n",
    "    data_path = \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\"\n",
    "    \n",
    "    # Collect all Parquet file paths\n",
    "    parquet_files = glob(f\"{data_path}/partition_id={k}/part-0.parquet\")\n",
    "    \n",
    "    print(f\"Processing partition {k}\")\n",
    "\n",
    "    # Process each Parquet file\n",
    "    final_df = pl.concat([pl.read_parquet(file) for file in parquet_files])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Final DataFrame shape: {final_df.shape}\")\n",
    "    \n",
    "    # Fill NaNs with forward fill\n",
    "    final_df = final_df.fill_null(strategy=\"forward\").fill_null(strategy=\"backward\")\n",
    "    \n",
    "    # List of responder columns\n",
    "    responder_columns = [f\"responder_{i}\" for i in range(9)]\n",
    "    \n",
    "    # Apply the lagging for each responder column\n",
    "    for responder in responder_columns:\n",
    "        lagged_column_name = f\"{responder}_lag_1\"\n",
    "        final_df = final_df.with_columns(\n",
    "            pl.col(responder)\n",
    "            .shift(1)\n",
    "            .over([\"time_id\", \"symbol_id\"])\n",
    "            .alias(lagged_column_name)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e37784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T14:55:10.812591Z",
     "iopub.status.busy": "2024-11-26T14:55:10.812310Z",
     "iopub.status.idle": "2024-11-26T14:55:13.319311Z",
     "shell.execute_reply": "2024-11-26T14:55:13.318582Z"
    },
    "papermill": {
     "duration": 2.512495,
     "end_time": "2024-11-26T14:55:13.321287",
     "exception": false,
     "start_time": "2024-11-26T14:55:10.808792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = final_df.fill_null(strategy=\"forward\").fill_null(strategy=\"backward\")\n",
    "final_df = final_df.fill_null(0)\n",
    "df = final_df.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63dd5627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T14:55:13.328151Z",
     "iopub.status.busy": "2024-11-26T14:55:13.327884Z",
     "iopub.status.idle": "2024-11-26T14:55:14.232173Z",
     "shell.execute_reply": "2024-11-26T14:55:14.231302Z"
    },
    "papermill": {
     "duration": 0.909874,
     "end_time": "2024-11-26T14:55:14.234172",
     "exception": false,
     "start_time": "2024-11-26T14:55:13.324298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_id  time_id  symbol_id    weight  feature_00  feature_01  feature_02  \\\n",
      "0      680        0          0  2.298160    0.851814    1.197591    0.219422   \n",
      "1      680        0          1  3.928745    0.534441    1.079740    0.038748   \n",
      "2      680        0          2  1.340433   -0.227643    0.764146   -0.243349   \n",
      "3      680        0          3  1.695526    0.267686    1.193612   -0.388798   \n",
      "4      680        0          5  2.700766    0.952372    0.861269   -0.375405   \n",
      "\n",
      "   feature_03  feature_04  feature_05  ...  responder_8  responder_0_lag_1  \\\n",
      "0    0.411698    2.057359   -0.542597  ...     1.101371          -0.304665   \n",
      "1    0.275343    2.135057   -0.541966  ...     1.986971          -0.304665   \n",
      "2    0.247027    2.347248   -0.478477  ...    -0.049303          -0.304665   \n",
      "3    0.030673    2.175273   -0.408371  ...     3.031337          -0.304665   \n",
      "4    0.259099    2.497325   -0.618828  ...     2.073280          -0.304665   \n",
      "\n",
      "   responder_1_lag_1  responder_2_lag_1  responder_3_lag_1  responder_4_lag_1  \\\n",
      "0           0.164485          -0.205231           0.191064          -1.413209   \n",
      "1           0.164485          -0.205231           0.191064          -1.413209   \n",
      "2           0.164485          -0.205231           0.191064          -1.413209   \n",
      "3           0.164485          -0.205231           0.191064          -1.413209   \n",
      "4           0.164485          -0.205231           0.191064          -1.413209   \n",
      "\n",
      "   responder_5_lag_1  responder_6_lag_1  responder_7_lag_1  responder_8_lag_1  \n",
      "0           0.375675           0.929775          -1.574939           1.101371  \n",
      "1           0.375675           0.929775          -1.574939           1.101371  \n",
      "2           0.375675           0.929775          -1.574939           1.101371  \n",
      "3           0.375675           0.929775          -1.574939           1.101371  \n",
      "4           0.375675           0.929775          -1.574939           1.101371  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150e63e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T14:51:50.673334Z",
     "iopub.status.busy": "2024-11-26T14:51:50.673068Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-11-26T14:55:14.238335",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Placeholder for cross-correlation results\n",
    "cross_correlation_results = []\n",
    "\n",
    "# Subset the DataFrame to the first 1 million rows\n",
    "df = df.head(100_000)\n",
    "\n",
    "# Define features to lag and the lag range\n",
    "features = [col for col in df.columns if col.startswith('feature_')]\n",
    "print(features)\n",
    "\n",
    "time_lags = range(1, 11)  # Corresponds to -1 to -10 lags\n",
    "\n",
    "# Sort data by symbol_id, date_id, and time_id\n",
    "df = df.sort_values(by=['symbol_id', 'date_id', 'time_id'])\n",
    "\n",
    "# Backpropagate lagged features directly in the DataFrame\n",
    "for lag in time_lags:\n",
    "    for feature in features:\n",
    "        df[f\"{feature}_lag_{lag}\"] = np.nan  # Initialize new columns\n",
    "\n",
    "# Fill lagged values by propagating values from previous time_id or date_id\n",
    "for symbol_id in df['symbol_id'].unique():\n",
    "    symbol_data = df[df['symbol_id'] == symbol_id]\n",
    "    for lag in time_lags:\n",
    "        for feature in features:\n",
    "            lagged_col = f\"{feature}_lag_{lag}\"\n",
    "            # Shift values by `lag` within each group of `date_id`\n",
    "            df.loc[df['symbol_id'] == symbol_id, lagged_col] = symbol_data.groupby('date_id')[feature].shift(lag)\n",
    "\n",
    "# Compute cross-correlation for each feature and lag\n",
    "for lag in time_lags:\n",
    "    for feature in features:\n",
    "        lagged_col = f\"{feature}_lag_{lag}\"\n",
    "        # Calculate correlation only for rows where lagged values are not NaN\n",
    "        valid_rows = df[~df[lagged_col].isna()]\n",
    "        correlation = valid_rows[lagged_col].corr(valid_rows['responder_6'])\n",
    "        cross_correlation_results.append({\n",
    "            'lag': -lag,  # Negative lag for clarity\n",
    "            'feature': feature,\n",
    "            'cross_correlation': correlation\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "cross_correlation_df = pd.DataFrame(cross_correlation_results)\n",
    "\n",
    "# Sort results for better readability\n",
    "cross_correlation_df = cross_correlation_df.sort_values(by=['feature', 'lag'], ascending=[True, False])\n",
    "\n",
    "# Display results\n",
    "print(cross_correlation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47a414",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the top 50 cross-correlation results in descending order\n",
    "top_50_cross_correlations = cross_correlation_df.sort_values(by='cross_correlation', ascending=False).head(20)\n",
    "\n",
    "# Display the top 50 results\n",
    "print(top_50_cross_correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7390779",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by 'feature' and 'lag', then calculate the mean cross-correlation\n",
    "mean_cross_correlation = (\n",
    "    cross_correlation_df\n",
    "    .groupby(['feature', 'lag'])\n",
    "    .agg(mean_correlation=('cross_correlation', 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort the results for better readability\n",
    "mean_cross_correlation = mean_cross_correlation.sort_values(by='mean_correlation', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(mean_cross_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047802ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_cross_correlation =mean_cross_correlation.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadaca3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mean_cross_correlation.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424bc7e2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mean_cross_correlation.tail(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dd5bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c81195",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the correlation of all features with 'responder_1'\n",
    "correlations_with_responder_1 = correlation_matrix[\"responder_6\"].drop(\"responder_6\")\n",
    "# Sort correlations in descending order and get the top 10 features\n",
    "top_10_features = correlations_with_responder_1.abs().sort_values(ascending=False).head(100)\n",
    "\n",
    "# Display the result\n",
    "print(\"Top 10 Features Correlated with Responder_6:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506d58f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ceabf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T14:54:50.866201",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}