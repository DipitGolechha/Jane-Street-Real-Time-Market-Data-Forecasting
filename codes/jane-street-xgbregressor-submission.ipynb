{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1e889f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-28T20:51:59.281923Z",
     "iopub.status.busy": "2024-11-28T20:51:59.281450Z",
     "iopub.status.idle": "2024-11-28T20:52:00.665604Z",
     "shell.execute_reply": "2024-11-28T20:52:00.664620Z"
    },
    "papermill": {
     "duration": 1.391269,
     "end_time": "2024-11-28T20:52:00.668042",
     "exception": false,
     "start_time": "2024-11-28T20:51:59.276773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e23cc",
   "metadata": {
    "papermill": {
     "duration": 0.002535,
     "end_time": "2024-11-28T20:52:00.673513",
     "exception": false,
     "start_time": "2024-11-28T20:52:00.670978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in `jane_street_gateway` will run in a different container with direct access to the hidden test set and hand off the data timestep by timestep.\n",
    "\n",
    "\n",
    "\n",
    "Your code will always have access to the published copies of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b53c2c4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-28T20:52:00.680738Z",
     "iopub.status.busy": "2024-11-28T20:52:00.679950Z",
     "iopub.status.idle": "2024-11-28T20:52:02.408790Z",
     "shell.execute_reply": "2024-11-28T20:52:02.407748Z"
    },
    "papermill": {
     "duration": 1.7352,
     "end_time": "2024-11-28T20:52:02.411161",
     "exception": false,
     "start_time": "2024-11-28T20:52:00.675961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Global variables\n",
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "# Use dictionaries for efficient data access\n",
    "history_cache = {}\n",
    "lags_cache = {}\n",
    "\n",
    "train_flag = False\n",
    "training_data = None\n",
    "combined_training_data = pl.DataFrame()\n",
    "train_buffer = 0\n",
    "BUFFER_LIMIT = 1\n",
    "\n",
    "train_runs = 0\n",
    "TRAIN_RUN_LIMIT = 0\n",
    "\n",
    "loaded_model = None\n",
    "\n",
    "# Feature columns\n",
    "feature_columns = ['responder_3_lag_1', 'responder_8_lag_1', 'responder_7_lag_1', 'responder_4_lag_1', 'responder_5_lag_1',\n",
    "        'responder_0_lag_1', 'responder_2_lag_1', 'responder_1_lag_1', \n",
    "        'feature_06', 'feature_60', 'feature_49', 'feature_04', 'feature_07', \n",
    "        'feature_58', 'feature_59', 'feature_47', 'feature_51', 'feature_36', \n",
    "        'feature_52', 'feature_68', 'feature_13', 'feature_02', 'feature_05', \n",
    "        'feature_41', 'feature_01', 'time_id', 'feature_54', 'feature_40', \n",
    "        'feature_03', 'feature_55', 'feature_08', 'feature_19', 'feature_48', \n",
    "        'feature_00', 'feature_71', 'feature_66', 'feature_45']\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame:\n",
    "    global lags_, loaded_model, history_cache, lags_cache, train_flag, training_data, train_buffer, combined_training_data, BUFFER_LIMIT, feature_columns, train_runs, TRAIN_RUN_LIMIT\n",
    "\n",
    "    # Extract date_id from test data\n",
    "    date_id = test['date_id'][0]\n",
    "\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "        lags_cache[date_id] = lags\n",
    "        train_flag = True\n",
    "\n",
    "    if loaded_model is None:\n",
    "        # Load the model once\n",
    "        with open(\"/kaggle/input/xgboostregressor/other/default/1/saved_model_xgboost (2).pkl\", \"rb\") as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "\n",
    "    # Join test with lags_\n",
    "    if lags_ is not None:\n",
    "        combined_data = test.join(lags_, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "    else:\n",
    "        combined_data = test\n",
    "\n",
    "    combined_data = combined_data.fill_null(0)  # Fill nulls with zeros\n",
    "\n",
    "    # Prepare the input features\n",
    "    X_pred = combined_data.select(feature_columns).to_numpy()\n",
    "    X_pred = np.nan_to_num(X_pred)  # Replace any remaining NaNs with zeros\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = loaded_model.predict(X_pred)\n",
    "\n",
    "    # Add predictions to combined_data\n",
    "    combined_data = combined_data.with_columns(pl.Series(name=\"responder_6\", values=predictions))\n",
    "\n",
    "    # Prepare the output\n",
    "    predictions_df = combined_data.select('row_id', 'responder_6')\n",
    "\n",
    "    # Update history_cache\n",
    "    history_cache[date_id] = test\n",
    "\n",
    "    # Training\n",
    "    if train_flag:\n",
    "        # Only allow model training once we have enough data\n",
    "        if len(history_cache) <= 1:\n",
    "            train_flag = False\n",
    "        else:\n",
    "            start = time.time()\n",
    "\n",
    "            prev_date_id = date_id - 1\n",
    "\n",
    "            # Ground truths: lags_ with date_id - 1\n",
    "            ground_truths = lags_.with_columns(\n",
    "                (pl.col(\"date_id\") - 1).alias(\"date_id\")\n",
    "            )\n",
    "\n",
    "            # Get previous test data\n",
    "            if prev_date_id in history_cache:\n",
    "                prev_test_data = history_cache[prev_date_id]\n",
    "\n",
    "                training_data = ground_truths.join(prev_test_data, on=[\"date_id\", \"time_id\",\"symbol_id\"], how=\"left\")\n",
    "\n",
    "                # Rename columns\n",
    "                rename_mapping = {f\"responder_{i}_lag_1\": f\"responder_{i}\" for i in range(9)}\n",
    "                training_data = training_data.rename(rename_mapping)\n",
    "\n",
    "                # Also join with previous lags data\n",
    "                if prev_date_id in lags_cache:\n",
    "                    prev_lags_data = lags_cache[prev_date_id]\n",
    "                    training_data = training_data.join(prev_lags_data, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "\n",
    "                # Accumulate training data\n",
    "                if combined_training_data.is_empty():\n",
    "                    combined_training_data = training_data\n",
    "                else:\n",
    "                    combined_training_data = combined_training_data.vstack(training_data)\n",
    "\n",
    "                train_buffer += 1\n",
    "\n",
    "                if train_buffer >= BUFFER_LIMIT and train_runs < TRAIN_RUN_LIMIT:\n",
    "                    # Prepare training data\n",
    "                    # X_train = combined_training_data.select(feature_columns).to_numpy()\n",
    "                    # X_train = np.nan_to_num(X_train)\n",
    "                    X_train = combined_training_data.select(feature_columns).to_pandas()\n",
    "\n",
    "                    # print(X_train.columns)\n",
    "\n",
    "                    # y_train = combined_training_data.select([\"responder_6\"]).to_numpy().ravel()\n",
    "                    y_train = combined_training_data.select([\"responder_6\"])\n",
    "\n",
    "                    # Continue training the model\n",
    "                    loaded_model.fit(X_train, y_train, xgb_model=loaded_model)\n",
    "\n",
    "                    # Reset training data\n",
    "                    combined_training_data = pl.DataFrame()\n",
    "                    train_buffer = 0\n",
    "                    train_runs += 1\n",
    "\n",
    "                # Remove old data\n",
    "                del history_cache[prev_date_id]\n",
    "                del lags_cache[prev_date_id]\n",
    "\n",
    "            end = time.time()\n",
    "            print(f\"Total time taken: {end-start}\")\n",
    "            train_flag = False\n",
    "\n",
    "    # Ensure the output DataFrame has the correct columns\n",
    "    if isinstance(predictions_df, pl.DataFrame):\n",
    "        assert predictions_df.columns == ['row_id', 'responder_6']\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a Polars DataFrame')\n",
    "\n",
    "    # Confirm has as many rows as the test data.\n",
    "    assert len(predictions_df) == len(test)\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137edfae",
   "metadata": {
    "papermill": {
     "duration": 0.002118,
     "end_time": "2024-11-28T20:52:02.415767",
     "exception": false,
     "start_time": "2024-11-28T20:52:02.413649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When your notebook is run on the hidden test set, inference_server.serve must be called within 15 minutes of the notebook starting or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very first `predict` call, which does not have the usual 1 minute response deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95090f38",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-28T20:52:02.422402Z",
     "iopub.status.busy": "2024-11-28T20:52:02.421374Z",
     "iopub.status.idle": "2024-11-28T20:52:03.058310Z",
     "shell.execute_reply": "2024-11-28T20:52:03.057153Z"
    },
    "papermill": {
     "duration": 0.6427,
     "end_time": "2024-11-28T20:52:03.060685",
     "exception": false,
     "start_time": "2024-11-28T20:52:02.417985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:52:02] WARNING: /workspace/src/gbm/gbtree.cc:385: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "[20:52:02] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a06e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T20:52:03.067229Z",
     "iopub.status.busy": "2024-11-28T20:52:03.066843Z",
     "iopub.status.idle": "2024-11-28T20:52:03.082186Z",
     "shell.execute_reply": "2024-11-28T20:52:03.080966Z"
    },
    "papermill": {
     "duration": 0.021355,
     "end_time": "2024-11-28T20:52:03.084639",
     "exception": false,
     "start_time": "2024-11-28T20:52:03.063284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (39, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>responder_6</th></tr><tr><td>i64</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>0.138778</td></tr><tr><td>1</td><td>0.11631</td></tr><tr><td>2</td><td>0.208794</td></tr><tr><td>3</td><td>0.14146</td></tr><tr><td>4</td><td>0.015718</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>34</td><td>0.10175</td></tr><tr><td>35</td><td>0.417461</td></tr><tr><td>36</td><td>0.061081</td></tr><tr><td>37</td><td>0.102887</td></tr><tr><td>38</td><td>0.195636</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (39, 2)\n",
       "┌────────┬─────────────┐\n",
       "│ row_id ┆ responder_6 │\n",
       "│ ---    ┆ ---         │\n",
       "│ i64    ┆ f32         │\n",
       "╞════════╪═════════════╡\n",
       "│ 0      ┆ 0.138778    │\n",
       "│ 1      ┆ 0.11631     │\n",
       "│ 2      ┆ 0.208794    │\n",
       "│ 3      ┆ 0.14146     │\n",
       "│ 4      ┆ 0.015718    │\n",
       "│ …      ┆ …           │\n",
       "│ 34     ┆ 0.10175     │\n",
       "│ 35     ┆ 0.417461    │\n",
       "│ 36     ┆ 0.061081    │\n",
       "│ 37     ┆ 0.102887    │\n",
       "│ 38     ┆ 0.195636    │\n",
       "└────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile('submission.parquet'):\n",
    "    pl_sub = pl.read_parquet('submission.parquet')\n",
    "    display(pl_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26feb5b",
   "metadata": {
    "papermill": {
     "duration": 0.003409,
     "end_time": "2024-11-28T20:52:03.091668",
     "exception": false,
     "start_time": "2024-11-28T20:52:03.088259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "modelId": 174459,
     "modelInstanceId": 152004,
     "sourceId": 178442,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 174534,
     "modelInstanceId": 152082,
     "sourceId": 178533,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.10558,
   "end_time": "2024-11-28T20:52:03.715440",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-28T20:51:56.609860",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
